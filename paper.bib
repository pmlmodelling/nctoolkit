@article{Ishii2005,
abstract = {Data for the 20th century from the International Comprehensive Ocean and Atmosphere Data Set and the Kobe Collection have been used as input data for global objective analyses of sea-surface temperatures (SSTs) and other marine meteorological variables. This study seeks a better understanding of the historical marine meteorological data and an evaluation of the quality of the data in the Kobe Collection. Objective analyses yield gridded data that are less noisy than observed data, which facilitates handling of historical data. The observed data determine the quality of the objective analyses, and quality control specified for historical data is incorporated into the objective analysis to reduce artificial errors. The objective analyses are based on optimum interpolation and reconstruction with empirical orthogonal functions. The final database produced in this study not only contains analysed values, but also analysis errors and data distributions at each time step of the objective analyses. The analysis database contains amp le information on historical observations, as well as signals of marine climate variations during the century. Time series of global mean marine temperatures and cloud cover include trends linked to global warming, and local peaks appear commonly in all the time series around the 1940s. Sea-level pressure and sea-surface wind fields show significant linear trends at high latitudes and over the North Pacific Ocean respectively. These trends seem to be artificial. An SST analysis used widely in climatological studies was verified against HadISST from the Hadley Centre and an SST analysis derived from satellite and in situ observations. El Ni{\~{n}}o and southern oscillation indices for the century are successfully reproduced, even though observations in the tropics are much rarer before 1950 than after 1950. Copyright {\textcopyright} 2005 Royal Meteorological Society.},
author = {Ishii, Masayoshi and Shouji, Akiko and Sugimoto, Satoshi and Matsumoto, Takanori},
doi = {10.1002/joc.1169},
file = {:users/modellers/rwi/Documents/Mendeley Desktop/Intl Journal of Climatology - 2005 - Ishii - Objective analyses of sea‐surface temperature and marine meteorological.pdf:pdf},
issn = {08998418},
journal = {International Journal of Climatology},
keywords = {ICOADS,Kobe Collection,Marine meteorology,Objective analysis,Optimum interpolation,Reconstruction,SST},
number = {7},
pages = {865--879},
title = {{Objective analyses of sea-surface temperature and marine meteorological variables for the 20th century using ICOADS and the Kobe Collection}},
volume = {25},
year = {2005}
}

@article{mckinney2011pandas,
  title={pandas: a foundational Python library for data analysis and statistics},
  author={McKinney, Wes and others},
  journal={Python for high performance and scientific computing},
  volume={14},
  number={9},
  pages={1--9},
  year={2011},
  publisher={Seattle}
}

@article{hunter2007matplotlib,
  title={Matplotlib: A 2D graphics environment},
  author={Hunter, John D},
  doi = {10.1109/MCSE.2007.55},
  journal={Computing in science \& engineering},
  volume={9},
  number={03},
  pages={90--95},
  year={2007},
  publisher={IEEE Computer Society}
}

@misc{eaton2003netcdf,
  title={NetCDF Climate and Forecast (CF) metadata conventions},
  author={Eaton, Brian and Gregory, Jonathan and Drach, Bob and Taylor, Karl and Hankin, Steve and Caron, John and Signell, Rich and Bentley, Phil and Rappa, Greg and H{\"o}ck, Heinke and others},
  year={2003},
  publisher={Version}
}

@misc{schulzweida_uwe_2022_7112925,
  author       = {Schulzweida, Uwe},
  title        = {CDO User Guide},
  month        = oct,
  year         = 2022,
  publisher    = {Zenodo},
  version      = {2.1.0},
  doi          = {10.5281/zenodo.7112925},
  url          = {https://doi.org/10.5281/zenodo.7112925}
}


@article{Hassell2017,
abstract = {The CF (Climate and Forecast) metadata conventions are designed to promote the creation, processing, and sharing of climate and forecasting data using Network Common Data Form (netCDF) files and libraries. The CF conventions provide a description of the physical meaning of data and of their spatial and temporal properties, but they depend on the netCDF file encoding which can currently only be fully understood and interpreted by someone familiar with the rules and relationships specified in the conventions documentation. To aid in development of CF-compliant software and to capture with a minimal set of elements all of the information contained in the CF conventions, we propose a formal data model for CF which is independent of netCDF and describes all possible CF-compliant data. Because such data will often be analysed and visualised using software based on other data models, we compare our CF data model with the ISO 19123 coverage model, the Open Geospatial Consortium CF netCDF standard, and the Unidata Common Data Model. To demonstrate that this CF data model can in fact be implemented, we present cf-python, a Python software library that conforms to the model and can manipulate any CF-compliant dataset.},
author = {Hassell, David and Gregory, Jonathan and Blower, Jon and Lawrence, Bryan N. and Taylor, Karl E.},
doi = {10.5194/gmd-10-4619-2017},
file = {:users/modellers/rwi/Documents/Mendeley Desktop/gmd-10-4619-2017.pdf:pdf},
issn = {19919603},
journal = {Geoscientific Model Development},
number = {12},
pages = {4619--4646},
title = {{A data model of the Climate and Forecast metadata conventions (CF-1.6) with a software implementation (cf-python v2.1)}},
volume = {10},
year = {2017}
}

@article{Hoyer2017,
abstract = {<p class="p1"> xarray is an open source project and Python package that provides a toolkit and data structures for N-dimensional labeled arrays. Our approach combines an application programing interface (API) inspired by pandas with the Common Data Model for self-described scientific data. Key features of the xarray package include label-based indexing and arithmetic, interoperability with the core scientific Python packages (e.g., pandas, NumPy, Matplotlib), out-of-core computation on datasets that don't fit into memory, a wide range of serialization and input/output (I/O) options, and advanced multi-dimensional data manipulation tools such as group-by and resampling. xarray, as a data model and analytics toolkit, has been widely adopted in the geoscience community but is also used more broadly for multi-dimensional data analysis in physics, machine learning and finance.</p>},
author = {Hoyer, Stephan and Hamman, Joe},
doi = {10.5334/jors.148},
file = {:users/modellers/rwi/Documents/Mendeley Desktop/148-1-1826-1-10-20170405.pdf:pdf},
journal = {Journal of Open Research Software},
keywords = {data,data analysis,data handling,multidimensional,netcdf,pandas,python},
number = {1},
pages = {10},
title = {{xarray: N-D labeled Arrays and Datasets in Python}},
volume = {5},
year = {2017}
}

@article{Stevens2015,
abstract = {Abstract—Scientific visualization typically requires large amounts of custom coding that obscures the underlying principles of the work and makes it difficult to reproduce the results. Here we describe how the new HoloViews Python package, when combined with the ...\n},
author = {Stevens, Jean-Luc and Rudiger, Philipp and Bednar, James},
doi = {10.25080/majora-7b98e3ed-00a},
file = {:users/modellers/rwi/Documents/Mendeley Desktop/5d712e22c6c838f379d0d11509e56eb4ef90.pdf:pdf},
journal = {Proceedings of the 14th Python in Science Conference},
number = {Scipy},
pages = {59--66},
title = {{HoloViews: Building Complex Visualizations Easily for Reproducible Science}},
year = {2015}
}

@article{Harris2020,
abstract = {Array programming provides a powerful, compact and expressive syntax for accessing, manipulating and operating on data in vectors, matrices and higher-dimensional arrays. NumPy is the primary array programming library for the Python language. It has an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. For example, in astronomy, NumPy was an important part of the software stack used in the discovery of gravitational waves1 and in the first imaging of a black hole2. Here we review how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring and analysing scientific data. NumPy is the foundation upon which the scientific Python ecosystem is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces and array objects. Owing to its central position in the ecosystem, NumPy increasingly acts as an interoperability layer between such array computation libraries and, together with its application programming interface (API), provides a flexible framework to support the next decade of scientific and industrial analysis.},
archivePrefix = {arXiv},
arxivId = {2006.10256},
author = {Harris, Charles R. and Millman, K. Jarrod and van der Walt, St{\'{e}}fan J. and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and van Kerkwijk, Marten H. and Brett, Matthew and Haldane, Allan and del R{\'{i}}o, Jaime Fern{\'{a}}ndez and Wiebe, Mark and Peterson, Pearu and G{\'{e}}rard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
doi = {10.1038/s41586-020-2649-2},
eprint = {2006.10256},
file = {:users/modellers/rwi/Documents/Mendeley Desktop/s41586-020-2649-2.pdf:pdf},
issn = {14764687},
journal = {Nature},
number = {7825},
pages = {357--362},
pmid = {32939066},
publisher = {Springer US},
title = {{Array programming with NumPy}},
url = {http://dx.doi.org/10.1038/s41586-020-2649-2},
volume = {585},
year = {2020}
}

@article{Petrie2021,
abstract = {The distribution of data contributed to the Coupled Model Intercomparison Project Phase 6 (CMIP6) is via the Earth System Grid Federation (ESGF). The ESGF is a network of internationally distributed sites that together work as a federated data archive. Data records from climate modelling institutes are published to the ESGF and then shared around the world. It is anticipated that CMIP6 will produce approximately 20 PB of data to be published and distributed via the ESGF. In addition to this large volume of data a number of value-added CMIP6 services are required to interact with the ESGF; for example the citation and errata services both interact with the ESGF but are not a core part of its infrastructure. With a number of interacting services and a large volume of data anticipated for CMIP6, the CMIP Data Node Operations Team (CDNOT) was formed. The CDNOT coordinated and implemented a series of CMIP6 preparation data challenges to test all the interacting components in the ESGF CMIP6 software ecosystem. This ensured that when CMIP6 data were released they could be reliably distributed.},
author = {Petrie, Ruth and Denvil, S{\'{e}}bastien and Ames, Sasha and Levavasseur, Guillaume and Fiore, Sandro and Allen, Chris and Antonio, Fabrizio and Berger, Katharina and Bretonni{\`{e}}re, Pierre Antoine and Cinquini, Luca and Dart, Eli and Dwarakanath, Prashanth and Druken, Kelsey and Evans, Ben and Franchist{\'{e}}guy, Laurent and Gardoll, S{\'{e}}bastien and Gerbier, Eric and Greenslade, Mark and Hassell, David and Iwi, Alan and Juckes, Martin and Kindermann, Stephan and Lacinski, Lukasz and Mirto, Maria and {Ben Nasser}, Atef and Nassisi, Paola and Nienhouse, Eric and Nikonov, Sergey and Nuzzo, Alessandra and Richards, Clare and Ridzwan, Syazwan and Rixen, Michel and Serradell, Kim and Snow, Kate and Stephens, Ag and Stockhause, Martina and Vahlenkamp, Hans and Wagner, Rick},
doi = {10.5194/gmd-14-629-2021},
file = {:users/modellers/rwi/Documents/Mendeley Desktop/gmd-14-629-2021.pdf:pdf},
issn = {19919603},
journal = {Geoscientific Model Development},
number = {1},
pages = {629--644},
title = {{Coordinating an operational data distribution network for CMIP6 data}},
volume = {14},
year = {2021}
}

@article{ONeill2016,
abstract = {Projections of future climate change play a fundamental role in improving understanding of the climate system as well as characterizing societal risks and response options. The Scenario Model Intercomparison Project (ScenarioMIP) is the primary activity within Phase 6 of the Coupled Model Intercomparison Project (CMIP6) that will provide multi-model climate projections based on alternative scenarios of future emissions and land use changes produced with integrated assessment models. In this paper, we describe ScenarioMIP's objectives, experimental design, and its relation to other activities within CMIP6. The ScenarioMIP design is one component of a larger scenario process that aims to facilitate a wide range of integrated studies across the climate science, integrated assessment modeling, and impacts, adaptation, and vulnerability communities, and will form an important part of the evidence base in the forthcoming Intergovernmental Panel on Climate Change (IPCC) assessments. At the same time, it will provide the basis for investigating a number of targeted science and policy questions that are especially relevant to scenario-based analysis, including the role of specific forcings such as land use and aerosols, the effect of a peak and decline in forcing, the consequences of scenarios that limit warming to below 2 °C, the relative contributions to uncertainty from scenarios, climate models, and internal variability, and long-term climate system outcomes beyond the 21st century. To serve this wide range of scientific communities and address these questions, a design has been identified consisting of eight alternative 21st century scenarios plus one large initial condition ensemble and a set of long-term extensions, divided into two tiers defined by relative priority. Some of these scenarios will also provide a basis for variants planned to be run in other CMIP6-Endorsed MIPs to investigate questions related to specific forcings. Harmonized, spatially explicit emissions and land use scenarios generated with integrated assessment models will be provided to participating climate modeling groups by late 2016, with the climate model simulations run within the 2017-2018 time frame, and output from the climate model projections made available and analyses performed over the 2018-2020 period.},
author = {O'Neill, Brian C. and Tebaldi, Claudia and {Van Vuuren}, Detlef P. and Eyring, Veronika and Friedlingstein, Pierre and Hurtt, George and Knutti, Reto and Kriegler, Elmar and Lamarque, Jean Francois and Lowe, Jason and Meehl, Gerald A. and Moss, Richard and Riahi, Keywan and Sanderson, Benjamin M.},
doi = {10.5194/gmd-9-3461-2016},
file = {:users/modellers/rwi/Documents/Mendeley Desktop/gmd-9-3461-2016.pdf:pdf},
issn = {19919603},
journal = {Geoscientific Model Development},
number = {9},
pages = {3461--3482},
title = {{The Scenario Model Intercomparison Project (ScenarioMIP) for CMIP6}},
volume = {9},
year = {2016}
}

@article{Bates2018,
abstract = {Ecologists must understand how marine life responds to changing local conditions, rather than to overall global temperature rise, say Amanda E. Bates and 16 colleagues. Ecologists must understand how marine life responds to changing local conditions, rather than to overall global temperature rise.},
author = {Bates, Amanda E. and Helmuth, Brian and Burrows, Michael T. and Duncan, Murray I. and Garrabou, Joaquim and Guy-Haim, Tamar and Lima, Fernando and Queiros, Ana M. and Seabra, Rui and Marsh, Robert and Belmaker, Jonathan and Bensoussan, Nathaniel and Dong, Yunwei and Mazaris, Antonios D. and Smale, Dan and Wahl, Martin and Rilov, Gil},
doi = {10.1038/d41586-018-05869-5},
file = {:users/modellers/rwi/Documents/Mendeley Desktop/d41586-018-05869-5.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
keywords = {Climate change,Conservation biology,Ecology,Ocean sciences},
month = {aug},
number = {7718},
pages = {299--301},
publisher = {Nature Publishing Group},
title = {{Biologists ignore ocean weather at their peril}},
url = {http://www.nature.com/articles/d41586-018-05869-5},
volume = {560},
year = {2018}
}
